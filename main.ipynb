{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages to Import\n",
    "from threading import Thread\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import fftconvolve\n",
    "import IPython\n",
    "import pyroomacoustics as pra\n",
    "import csv\n",
    "from itertools import combinations\n",
    "import scipy.io as sio\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreadWithReturnValue(Thread):\n",
    "    \"\"\" \n",
    "    Created a Thread subclass. It is a workable doaround,\n",
    "    but it accesses \"private\" data structures that are specific to Thread implementation, so \n",
    "    things will get a little hairy.\n",
    "    \"\"\"\n",
    "    def __init__(self, group=None, target=None, name=None,\n",
    "                 args=(), kwargs={}, Verbose=None):\n",
    "        Thread.__init__(self, group, target, name, args, kwargs)\n",
    "        self._return = None\n",
    "    def run(self):\n",
    "        \n",
    "        \"\"\" Runs the function in a specified for the thread. \"\"\"\n",
    "        # If the target function is specified\n",
    "        if self._target is not None:\n",
    "            \n",
    "            # Run the function \n",
    "            self._return = self._target(*self._args,\n",
    "                                                **self._kwargs)\n",
    "            \n",
    "    def join(self, *args):\n",
    "        \"\"\" Returns the value of target function running in the thread. \"\"\"\n",
    "        \n",
    "        Thread.join(self, *args)\n",
    "        return self._return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(source_name):\n",
    "    \"\"\" Returns the data depending on the cycle number related and the specific sound source.\n",
    "    \n",
    "        Keyword arugments:\n",
    "        \n",
    "        source_name -- specifies each sound cycle \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Create a dictionary with all cycles: Regular S1 and S1 (top) Recovered S1 and S2 (bottom)\n",
    "    source_name_dict = {f'S{x}_Cycle{y}': [f'S{x}/S{x}_Cycle{y}', f'S{x}'] for x in range(1,3) for y in range(24)} \n",
    "    #source_name_dict = {f'S{x}_Cycle{y}': [f'Recovered_S{x}/S{x}_Cycle{y}', f'S{x}'] for x in range(1,3) for y in range(24)}\n",
    "    \n",
    "    # Match the correct data with the name\n",
    "    for key in source_name_dict.keys():\n",
    "        if source_name == key:\n",
    "            data = sio.loadmat(source_name_dict[key][0])\n",
    "            sound_data = data[source_name_dict[key][1]]\n",
    "    \n",
    "    # Return the sound data\n",
    "    return sound_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid(*args):  \n",
    "    \n",
    "    \"\"\" Returns the center of n number of microphones. \n",
    "    \n",
    "    Keyword Arguments:\n",
    "    \n",
    "    args -- location of each n microphone \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Initiate \n",
    "    microphone_array = np.zeros((len(args), len(args[1])))\n",
    "    \n",
    "    # Converts micrphone locations into an array\n",
    "    for i in range(len(args)):\n",
    "        microphone_array[i,:] = np.array(args[i])\n",
    "   \n",
    "    # Finds the centroid\n",
    "    return np.sum(microphone_array, axis=0)/len(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mic_run(data, *args):\n",
    "    \n",
    "    \"\"\" Returns each of the n microphone locations and the signals list corresponding to the specific microphone.\n",
    "        Note: The microphone locations are under a new coordinate system in relation to the center of the box\n",
    "              (whose center = [(0.34925/2),(0.219964/2),(0.2413/2)] is the origin)\n",
    "    \n",
    "        Keyword arguments:\n",
    "            data -- the signal associated with each microphone\n",
    "            args -- list of the microphones \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Empty Lists\n",
    "    signal_list = []\n",
    "    mic_location = []\n",
    "    \n",
    "    # Dictionary of the microphone locations and their respective signals\n",
    "    # Note: order is #mic number (from 1 -12), followed by location of channel (to get actual signal)\n",
    "    microphones_locations_dict = dict({\n",
    "        'mic1': [[-0.102235, -0.109982, 0.056388], data[0]],  \n",
    "        'mic2': [[-0.102235, -0.109982, 0.001524],  data[1]],\n",
    "        'mic3': [[-0.102235, -0.109982, -0.053340], data[2]], \n",
    "        'mic4': [[-0.102235, -0.109982, -0.108204], data[3]],\n",
    "        'mic5': [[-0.052197, -0.109982, 0.056388], data[4]],\n",
    "        'mic6': [[-0.052197, -0.109982, 0.001524], data[5]],\n",
    "        'mic7': [[-0.052197, -0.109982, -0.053340], data[6]],\n",
    "        'mic8': [[-0.052197, -0.109982, -0.108204], data[7]],\n",
    "        'mic9': [[-0.027304, -0.109982, 0.056388], data[8]],\n",
    "        'mic10': [[-0.027304, -0.109982, 0.001524], data[9]],\n",
    "        'mic11': [[-0.027304, -0.109982, -0.053340], data[10]],\n",
    "        'mic12': [[-0.027304, -0.109982, -0.108204], data[11]]\n",
    "        }) \n",
    "\n",
    "    # Look for a match between the dictionary of microphone locations and the microphone in the list\n",
    "    for arg in args:\n",
    "        for key in microphones_locations_dict.keys():\n",
    "            if arg == key:\n",
    "                # Record the location\n",
    "                mic_location.append(microphones_locations_dict[key][0])\n",
    "                \n",
    "                # Record the signal\n",
    "                signal_list.append(microphones_locations_dict[key][1])\n",
    "    \n",
    "   # Return the whole signal list as well all the specific microphone locations\n",
    "    return signal_list, mic_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_of_arrivals(speed_sound,signal_list,algo_name, *mic_location):\n",
    "\n",
    "    \"\"\" Returns an azimuth and co-latitude for each pair of microphones. \n",
    "\n",
    "        Keyword arugments:\n",
    "\n",
    "            sound_speed -- Specific speed of sound\n",
    "            signal_list -- the microphone signals\n",
    "            algo_name -- Specific distance of arrival (DOA) method\n",
    "            mic_location -- location of each microphone\n",
    "    \"\"\"\n",
    "    \n",
    "    #Constants \n",
    "    fs = 16000  # sampling frequency\n",
    "    nfft = 256  # FFT size\n",
    "    \n",
    "    # Add 3-microphone array in [x,y,z] order\n",
    "    R = np.vstack(list(zip(*mic_location)))\n",
    "    \n",
    "    # Create an array of a short fourier transformed frequency signal\n",
    "    X = np.array([pra.stft(signal, nfft, nfft//2,transform=np.fft.rfft).T for signal in signal_list])\n",
    "    \n",
    "    # Frequency Range\n",
    "    freq_range = [0,250]\n",
    "\n",
    "    # Construct the new DOA object\n",
    "    doa = pra.doa.algorithms[algo_name](L=R, fs=fs, nfft=nfft, c=sound_speed, num_src=1, max_four=4,\n",
    "    dim=3,azimuth=np.linspace(-180.,180.,360)*np.pi/180,\n",
    "    colatitude=np.linspace(-90.,90.,180)*np.pi/180)\n",
    "    \n",
    "    # Locate the sources\n",
    "    doa.locate_sources(X, freq_range=freq_range)\n",
    "    \n",
    "    # Return all in radians\n",
    "    return doa.azimuth_recon, doa.colatitude_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(sound_speed,algo_name,sound_data,combinations_number,S1_bool,source_name):\n",
    "    \n",
    "    \"\"\" Returns list of points that are either close to the point or the exact point itself.\n",
    "    \n",
    "        Keyword arguments:\n",
    "        \n",
    "            sound_speed -- specific speed of sound\n",
    "            algo_name -- specific distance of arrival (DOA) method to call\n",
    "            sound_data -- specific data to perform the localizing\n",
    "            combinations_number -- number of microphone to use\n",
    "            S1_bool -- flag to indicate whether to find S1 or S2 sound source\n",
    "            source_name -- indicates S1 or S2 and what specific cycle\n",
    "    \"\"\"\n",
    "    \n",
    "     # Optimization:\n",
    "    if S1_bool:\n",
    "        # List of specific microphones to quickly find S1\n",
    "        mics = ['mic'+str(i) for i in [2,3,4,6,7,8]]\n",
    "\n",
    "    else:\n",
    "        # List of specific microphones to quickly find S2\n",
    "        mics = ['mic'+str(i) for i in range(1,13)]\n",
    "        \n",
    "        #mics = ['mic'+str(i) for i in [1,2,5,6,10,11]]\n",
    "        #mic = ['mic'+str(i) for i in [2,3,6,7,10,11]]\n",
    "        \n",
    "        # Past MIC combinations\n",
    "        #mics = ['mic'+str(i) for i in [1,2,5,6,10,11]] --> NADA\n",
    "        #mics = ['mic'+str(i) for i in [1,2,3,5,6,7]] --> All cycles: NADA\n",
    "        #mics = ['mic'+str(i) for i in [5,6,7,10,11]] --> NADA\n",
    "    # TRASH\n",
    "    #mics = ['mic'+str(i) for i in range(1,13)]\n",
    "    \n",
    "    # Creates a list of N microphone-combinations\n",
    "    mic_list=list(combinations(mics,combinations_number))\n",
    "    \n",
    "    # number of mic pair splits to run \n",
    "    splits = len(mic_list)//5\n",
    "    \n",
    "    # Split up the mic list\n",
    "    mic_split_list = [mic_list[i*splits:(i+1)*splits] for i in range((len(mic_list)+splits-1)//splits)]\n",
    "    \n",
    "    # Store the final output\n",
    "    outputs_list = []\n",
    "\n",
    "    # Constants\n",
    "    tol = 3e-3\n",
    "    r = np.arange(0,0.5,tol)[:, np.newaxis]\n",
    "\n",
    "    for j in range(splits):\n",
    "              \n",
    "        # Pick the signal array and the associated pair of n microphone combinations\n",
    "        # Note: Multi-threaded the mic_run function for faster use\n",
    "        twrv1 = ThreadWithReturnValue(target=mic_run, args=(sound_data, *mic_split_list[0][j]))\n",
    "        twrv2 = ThreadWithReturnValue(target=mic_run, args=(sound_data, *mic_split_list[1][j]))\n",
    "        twrv3 = ThreadWithReturnValue(target=mic_run, args=(sound_data, *mic_split_list[2][j]))\n",
    "        twrv4 = ThreadWithReturnValue(target=mic_run, args=(sound_data, *mic_split_list[3][j]))\n",
    "        twrv5 = ThreadWithReturnValue(target=mic_run, args=(sound_data, *mic_split_list[4][j]))\n",
    "        #twrv6 = ThreadWithReturnValue(target=mic_run, args=(sound_data, *mic_split_list[5][j]))\n",
    "\n",
    "        twrv1.start()\n",
    "        twrv2.start()\n",
    "        twrv3.start()\n",
    "        twrv4.start()\n",
    "        twrv5.start()\n",
    "        #twrv6.start()\n",
    "        \n",
    "        # Return signal and microphone locations\n",
    "        [signal_1, mic_locations_1] = twrv1.join()\n",
    "        [signal_2, mic_locations_2] = twrv2.join()\n",
    "        [signal_3, mic_locations_3] = twrv3.join()\n",
    "        [signal_4, mic_locations_4] = twrv4.join()\n",
    "        [signal_5, mic_locations_5] = twrv5.join()\n",
    "        #[signal_6, mic_locations_6] = twrv6.join()\n",
    "   \n",
    "        # Find the centriods of the pairs of n microphone combinations\n",
    "        twrv7 = ThreadWithReturnValue(target=centroid, args=(mic_locations_1))\n",
    "        twrv8 = ThreadWithReturnValue(target=centroid, args=(mic_locations_2))\n",
    "        twrv9 = ThreadWithReturnValue(target=centroid, args=(mic_locations_3))\n",
    "        twrv10 = ThreadWithReturnValue(target=centroid, args=(mic_locations_4))\n",
    "        twrv11 = ThreadWithReturnValue(target=centroid, args=(mic_locations_5))\n",
    "        #twrv12 = ThreadWithReturnValue(target=centroid, args=(mic_locations_6))\n",
    "\n",
    "        twrv7.start()\n",
    "        twrv8.start()\n",
    "        twrv9.start()\n",
    "        twrv10.start()\n",
    "        twrv11.start()\n",
    "        #twrv12.start()\n",
    "        \n",
    "        # Return the centeriods\n",
    "        centroid_1 = twrv7.join()\n",
    "        centroid_2 = twrv8.join()\n",
    "        centroid_3 = twrv9.join()\n",
    "        centroid_4 = twrv10.join()\n",
    "        centroid_5 = twrv11.join()\n",
    "        #centroid_6 = twrv12.join()\n",
    "        \n",
    "        # Perform the distance of arrival methods to find closest azimuth and colatitude angles\n",
    "        twrv13 = ThreadWithReturnValue(target = difference_of_arrivals, args=(sound_speed,signal_1,algo_name,*mic_locations_1))\n",
    "        twrv14 = ThreadWithReturnValue(target = difference_of_arrivals, args=(sound_speed,signal_2,algo_name,*mic_locations_2))\n",
    "        twrv15 = ThreadWithReturnValue(target = difference_of_arrivals, args=(sound_speed,signal_3,algo_name,*mic_locations_3))\n",
    "        twrv16 = ThreadWithReturnValue(target = difference_of_arrivals, args=(sound_speed,signal_4,algo_name,*mic_locations_4))\n",
    "        twrv17 = ThreadWithReturnValue(target = difference_of_arrivals, args=(sound_speed,signal_5,algo_name,*mic_locations_5))\n",
    "        #twrv18 = ThreadWithReturnValue(target = difference_of_arrivals, args=(sound_speed,signal_6,algo_name,*mic_locations_6))\n",
    "        \n",
    "        twrv13.start()\n",
    "        twrv14.start()\n",
    "        twrv15.start()\n",
    "        twrv16.start()\n",
    "        twrv17.start()\n",
    "        #twrv18.start()\n",
    "        \n",
    "        # Desired angles \n",
    "        azimuth_recon_1, colatitude_recon_1 = twrv13.join()\n",
    "        azimuth_recon_2, colatitude_recon_2 = twrv14.join()\n",
    "        azimuth_recon_3, colatitude_recon_3 = twrv15.join()\n",
    "        azimuth_recon_4, colatitude_recon_4 = twrv16.join()\n",
    "        azimuth_recon_5, colatitude_recon_5 = twrv17.join()\n",
    "        #azimuth_recon_6, colatitude_recon_6 = twrv18.join()\n",
    "        \n",
    "        # Desired cartesian coordinates\n",
    "        cartesian_1 = np.array([np.cos(azimuth_recon_1)*np.sin(colatitude_recon_1),np.sin(azimuth_recon_1)*np.sin(colatitude_recon_1),np.cos(colatitude_recon_1)])\n",
    "        cartesian_2 = np.array([np.cos(azimuth_recon_2)*np.sin(colatitude_recon_2),np.sin(azimuth_recon_2)*np.sin(colatitude_recon_2),np.cos(colatitude_recon_2)])\n",
    "        cartesian_3 = np.array([np.cos(azimuth_recon_3)*np.sin(colatitude_recon_3),np.sin(azimuth_recon_3)*np.sin(colatitude_recon_3),np.cos(colatitude_recon_3)])\n",
    "        cartesian_4 = np.array([np.cos(azimuth_recon_4)*np.sin(colatitude_recon_4),np.sin(azimuth_recon_4)*np.sin(colatitude_recon_4),np.cos(colatitude_recon_4)])\n",
    "        cartesian_5 = np.array([np.cos(azimuth_recon_5)*np.sin(colatitude_recon_5),np.sin(azimuth_recon_5)*np.sin(colatitude_recon_5),np.cos(colatitude_recon_5)])\n",
    "        #cartesian_6 = np.array([np.cos(azimuth_recon_6)*np.sin(colatitude_recon_6),np.sin(azimuth_recon_6)*np.sin(colatitude_recon_6),np.cos(colatitude_recon_6)])\n",
    "        \n",
    "        # Re-center them via adding the centroid\n",
    "        estimate_1 = r*cartesian_1.T + np.array(centroid_1)[np.newaxis,:] \n",
    "        estimate_2 = r*cartesian_2.T + np.array(centroid_2)[np.newaxis,:]\n",
    "        estimate_3 = r*cartesian_3.T + np.array(centroid_3)[np.newaxis,:] \n",
    "        estimate_4 = r*cartesian_4.T + np.array(centroid_4)[np.newaxis,:]\n",
    "        estimate_5 = r*cartesian_5.T + np.array(centroid_5)[np.newaxis,:] \n",
    "        #estimate_6 = r*cartesian_6.T + np.array(centroid_6)[np.newaxis,:]\n",
    "        \n",
    "        # Add to an output list\n",
    "        outputs_list.extend((estimate_1, estimate_2, estimate_3, estimate_4, estimate_5)) #, estimate_6))\n",
    "    \n",
    "    # Make a numpy array of them \n",
    "    all_estimates = np.array(outputs_list)\n",
    "    \n",
    "    # Reshape them to (_, 3) which is proper format for the tree\n",
    "    total_array = np.reshape(all_estimates,(all_estimates.shape[0]*all_estimates.shape[1], all_estimates.shape[2]))\n",
    "    \n",
    "    # Put the whole list into a tree data data structure\n",
    "    tree = spatial.KDTree(total_array)\n",
    "    \n",
    "    if S1_bool:\n",
    "        # Find the points closest to where S1 is\n",
    "        indices_S1 = tree.query_ball_point([-0.110925,-0.003482,-0.06065], 2.5e-2)\n",
    "        estimate = (total_array[indices_S1][j] for j in range(len(indices_S1)))\n",
    "    else:\n",
    "        # Find the points closest to where S2 is\n",
    "        indices_S2 = tree.query_ball_point([-0.165225,-0.014282,-0.06565], 2.5e-2) \n",
    "        estimate = (total_array[indices_S2][j] for j in range(len(indices_S2)))\n",
    "    \n",
    "    # Write to a csv file to save the data\n",
    "    filename = 'mic_'+str(combinations_number)+'_'+str(source_name)+'_sound_source_localization_c'+str(sound_speed)+'_'+str(algo_name)+'_KDTREE_shortcut_2_test_multithread.csv'\n",
    "    with open(filename, mode='w') as sound_source_file:\n",
    "        writer = csv.writer(sound_source_file,delimiter=',')\n",
    "\n",
    "        # First Row of Data, names of the columns\n",
    "        writer.writerow(['X Location', 'Y Location', 'Z Location'])\n",
    "\n",
    "        # Write the rest of the results\n",
    "        # Note they have not been converted back into correct x,y,z coordinates\n",
    "        writer.writerows(estimate)\n",
    "\n",
    "    sound_source_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "    Performs the main script using all the sound data, specific speed of sound, \n",
    "    the names of the distance of arrival methods, and number of combinations of microphone pairs \n",
    "    \"\"\"\n",
    "    # Speed of sound\n",
    "    sound_speed = 30\n",
    "    \n",
    "    # Number of Pairs of Microphone Combinations\n",
    "    combinations_number = 3\n",
    "    \n",
    "    # Data: Number of Cycles for each Sound Source\n",
    "    cycles = ['Cycle'+str(i) for i in range(3,24)] \n",
    "    soundSources = ['S'+str(i) for i in range(2,3)] \n",
    "    sound_list = [soundSource+'_'+cycle for soundSource in soundSources for cycle in cycles]\n",
    "    \n",
    "    #DEBUG:\n",
    "    S1_bool = False\n",
    "    \n",
    "#     # When to find S1 and S2\n",
    "#     S1_bool = True\n",
    "    \n",
    "    # Now test all the algorithms available\n",
    "    algo_names = ['SRP','MUSIC','TOPS']\n",
    "    \n",
    "    for source_name in sound_list:\n",
    "        for algo_name in algo_names:\n",
    "            \n",
    "#             # Check if name is S2\n",
    "#             if source_name in ['S'+str(i)+'_'+'Cycle'+str(j) for i in range(2,3) for j in range(24)]:\n",
    "#                 S1_bool = False\n",
    "            \n",
    "            # Get the Sound Data\n",
    "            sound_data = getData(source_name)\n",
    "\n",
    "            # Get the final results\n",
    "            main(sound_speed,algo_name,sound_data,combinations_number,S1_bool,source_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
