{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages to Import\n",
    "from threading import Thread\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import fftconvolve\n",
    "import IPython\n",
    "import pyroomacoustics as pra\n",
    "import csv\n",
    "from itertools import combinations\n",
    "import scipy.io as sio\n",
    "from scipy import spatial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreadWithReturnValue(Thread):\n",
    "    \"\"\" \n",
    "    Created a Thread subclass. It is a workable doaround,\n",
    "    but it accesses \"private\" data structures that are specific to Thread implementation, so \n",
    "    things will get a little hairy.\n",
    "    \"\"\"\n",
    "    def __init__(self, group=None, target=None, name=None,args=(), kwargs={}, Verbose=None):\n",
    "        \"\"\" Initializes the thread object. \"\"\"\n",
    "        \n",
    "        Thread.__init__(self, group, target, name, args, kwargs)\n",
    "        self._return = None\n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\" Runs the function if specified for the thread. \"\"\"\n",
    "        # If the target function is specified\n",
    "        if self._target is not None:\n",
    "            \n",
    "            # Run the function \n",
    "            self._return = self._target(*self._args, **self._kwargs)\n",
    "            \n",
    "    def join(self, *args):\n",
    "        \"\"\" Returns the value of target function running in the thread. \"\"\"\n",
    "        \n",
    "        Thread.join(self, *args)\n",
    "        return self._return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(source_name):\n",
    "    \"\"\" Returns the data depending on the cycle number related and the specific sound source.\n",
    "    \n",
    "        Keyword arugments:\n",
    "        \n",
    "        source_name -- specifies each sound cycle \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Create a dictionary with all cycles: Regular S1 and S1 (top) Recovered S1 and S2 (bottom)\n",
    "    #source_name_dict = {f'S{x}_Cycle{y}': [f'S{x}/S{x}_Cycle{y}', f'S{x}'] for x in range(1,3) for y in range(24)} \n",
    "    source_name_dict = {f'S{x}_Cycle{y}': [f'Recovered_S{x}/S{x}_Cycle{y}', f'S{x}'] for x in range(1,3) for y in range(24)}\n",
    "    \n",
    "    # Match the correct data with the name\n",
    "    for key in source_name_dict.keys():\n",
    "        if source_name == key:\n",
    "            data = sio.loadmat(source_name_dict[key][0])\n",
    "            sound_data = data[source_name_dict[key][1]]\n",
    "    \n",
    "    # Return the sound data\n",
    "    return sound_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid(*args):  \n",
    "    \n",
    "    \"\"\" Returns the center of n number of microphones. \n",
    "    \n",
    "    Keyword Arguments:\n",
    "    \n",
    "    args -- location of each n microphone \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Initiate \n",
    "    microphone_array = np.zeros((len(args), len(args[1])))\n",
    "    \n",
    "    # Converts micrphone locations into an array\n",
    "    for i in range(len(args)):\n",
    "        microphone_array[i,:] = np.array(args[i])\n",
    "   \n",
    "    # Finds the centroid\n",
    "    return np.sum(microphone_array, axis=0)/len(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mic_run(data, *args):\n",
    "    \n",
    "    \"\"\" Returns each of the n microphone locations and the signals list corresponding to the specific microphone.\n",
    "        Note: The microphone locations are under a new coordinate system in relation to the center of the box\n",
    "              (whose center = [(0.34925/2),(0.219964/2),(0.2413/2)] is the origin)\n",
    "    \n",
    "        Keyword arguments:\n",
    "            data -- the signal associated with each microphone\n",
    "            args -- list of the microphones \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Empty Lists\n",
    "    signal_list = []\n",
    "    mic_location = []\n",
    "    \n",
    "    # Dictionary of the microphone locations and their respective signals\n",
    "    # Note: order is #mic number (from 1 -12), followed by location of channel (to get actual signal)\n",
    "    microphones_locations_dict = dict({\n",
    "        'mic1': [[-0.102235, -0.109982, 0.056388], data[0]],  \n",
    "        'mic2': [[-0.102235, -0.109982, 0.001524],  data[1]],\n",
    "        'mic3': [[-0.102235, -0.109982, -0.053340], data[2]], \n",
    "        'mic4': [[-0.102235, -0.109982, -0.108204], data[3]],\n",
    "        'mic5': [[-0.052197, -0.109982, 0.056388], data[4]],\n",
    "        'mic6': [[-0.052197, -0.109982, 0.001524], data[5]],\n",
    "        'mic7': [[-0.052197, -0.109982, -0.053340], data[6]],\n",
    "        'mic8': [[-0.052197, -0.109982, -0.108204], data[7]],\n",
    "        'mic9': [[-0.027304, -0.109982, 0.056388], data[8]],\n",
    "        'mic10': [[-0.027304, -0.109982, 0.001524], data[9]],\n",
    "        'mic11': [[-0.027304, -0.109982, -0.053340], data[10]],\n",
    "        'mic12': [[-0.027304, -0.109982, -0.108204], data[11]]\n",
    "        }) \n",
    "\n",
    "    # Look for a match between the dictionary of microphone locations and the microphone in the list\n",
    "    for arg in args:\n",
    "        for key in microphones_locations_dict.keys():\n",
    "            if arg == key:\n",
    "                # Record the location\n",
    "                mic_location.append(microphones_locations_dict[key][0])\n",
    "                \n",
    "                # Record the signal\n",
    "                signal_list.append(microphones_locations_dict[key][1])\n",
    "    \n",
    "   # Return the whole signal list as well all the specific microphone locations\n",
    "    return signal_list, mic_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_of_arrivals(speed_sound,signal_list,algo_name, *mic_location):\n",
    "\n",
    "    \"\"\" Returns an azimuth and co-latitude for each pair of microphones. \n",
    "\n",
    "        Keyword arugments:\n",
    "\n",
    "            sound_speed -- Specific speed of sound\n",
    "            signal_list -- the microphone signals\n",
    "            algo_name -- Specific distance of arrival (DOA) method\n",
    "            mic_location -- location of each microphone\n",
    "    \"\"\"\n",
    "    \n",
    "    #Constants \n",
    "    fs = 16000  # sampling frequency\n",
    "    nfft = 256  # FFT size\n",
    "    \n",
    "    # Add 3-microphone array in [x,y,z] order\n",
    "    R = np.vstack(list(zip(*mic_location)))\n",
    "    \n",
    "    # Create an array of a short fourier transformed frequency signal\n",
    "    X = np.array([pra.stft(signal, nfft, nfft//2,transform=np.fft.rfft).T for signal in signal_list])\n",
    "    \n",
    "    # Frequency Range\n",
    "    freq_range = [0,250]\n",
    "    \n",
    "    # Construct the new DOA object\n",
    "    doa = pra.doa.algorithms[algo_name](L=R, fs=fs, nfft=nfft, c=sound_speed, num_src=1, max_four=4,\n",
    "    dim=3,azimuth=np.linspace(-180.,180.,360)*np.pi/180,\n",
    "    colatitude=np.linspace(-90.,90.,180)*np.pi/180)\n",
    "    \n",
    "    # Locate the sources\n",
    "    doa.locate_sources(X, freq_range=freq_range)\n",
    "    \n",
    "    # Return all in radians\n",
    "    return doa.azimuth_recon, doa.colatitude_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(sound_speed,algo_name,sound_data,combinations_number,S1_bool,source_name):\n",
    "    \n",
    "    \"\"\" Returns list of points that are either close to the point or the exact point itself.\n",
    "    \n",
    "        Keyword arguments:\n",
    "        \n",
    "            sound_speed -- specific speed of sound\n",
    "            algo_name -- specific distance of arrival (DOA) method to call\n",
    "            sound_data -- specific data to perform the localizing\n",
    "            combinations_number -- number of microphone to use\n",
    "            S1_bool -- flag to indicate whether to find S1 or S2 sound source\n",
    "            source_name -- indicates S1 or S2 and what specific cycle\n",
    "    \"\"\"\n",
    "    \n",
    "     # Optimization:\n",
    "    if S1_bool:\n",
    "        # List of specific microphones to quickly find S1 (where M and T are located)\n",
    "        mics = ['mic'+str(i) for i in [2,3,6,7,10,11]]\n",
    "        \n",
    "    else:\n",
    "        # List of specific microphones to quickly find S2 (where P and A are located)\n",
    "        mics = ['mic'+str(i) for i in [1,2,5,6,9,10]] \n",
    "  \n",
    "    # Creates a list of N microphone-combinations\n",
    "    mic_list=list(combinations(mics,combinations_number))\n",
    "    \n",
    "    # number of mic pair splits to run \n",
    "    splits = len(mic_list)//5\n",
    "    \n",
    "    # Split up the mic list into chunks of the same size\n",
    "    mic_split_list = [mic_list[i*splits:(i+1)*splits] for i in range((len(mic_list)+splits-1)//splits)]\n",
    "    \n",
    "    # Store the final output\n",
    "    outputs_list = []\n",
    "\n",
    "    # Constants: Tolerance and Radius\n",
    "    tol = 3e-3 \n",
    "    r = np.arange(0,0.5,tol)[:, np.newaxis]\n",
    "    \n",
    "    # Go through all the chunks in the multi-thread\n",
    "    for j in range(splits):\n",
    "              \n",
    "        # Pick the signal array and the associated pair of n microphone combinations\n",
    "        # Note: Multi-threaded the mic_run function for faster use\n",
    "        twrv1 = ThreadWithReturnValue(target=mic_run, args=(sound_data, *mic_split_list[0][j]))\n",
    "        twrv2 = ThreadWithReturnValue(target=mic_run, args=(sound_data, *mic_split_list[1][j]))\n",
    "        twrv3 = ThreadWithReturnValue(target=mic_run, args=(sound_data, *mic_split_list[2][j]))\n",
    "        twrv4 = ThreadWithReturnValue(target=mic_run, args=(sound_data, *mic_split_list[3][j]))\n",
    "        twrv5 = ThreadWithReturnValue(target=mic_run, args=(sound_data, *mic_split_list[4][j]))\n",
    "    \n",
    "        # Start the multi-thread\n",
    "        twrv1.start()\n",
    "        twrv2.start()\n",
    "        twrv3.start()\n",
    "        twrv4.start()\n",
    "        twrv5.start()\n",
    "        \n",
    "        # Return signal and microphone locations\n",
    "        [signal_1, mic_locations_1] = twrv1.join()\n",
    "        [signal_2, mic_locations_2] = twrv2.join()\n",
    "        [signal_3, mic_locations_3] = twrv3.join()\n",
    "        [signal_4, mic_locations_4] = twrv4.join()\n",
    "        [signal_5, mic_locations_5] = twrv5.join()\n",
    "   \n",
    "        # Find the centriods of the pairs of n microphone combinations\n",
    "        twrv7 = ThreadWithReturnValue(target=centroid, args=(mic_locations_1))\n",
    "        twrv8 = ThreadWithReturnValue(target=centroid, args=(mic_locations_2))\n",
    "        twrv9 = ThreadWithReturnValue(target=centroid, args=(mic_locations_3))\n",
    "        twrv10 = ThreadWithReturnValue(target=centroid, args=(mic_locations_4))\n",
    "        twrv11 = ThreadWithReturnValue(target=centroid, args=(mic_locations_5))\n",
    "\n",
    "        twrv7.start()\n",
    "        twrv8.start()\n",
    "        twrv9.start()\n",
    "        twrv10.start()\n",
    "        twrv11.start()\n",
    "        \n",
    "        # Return the centeriods\n",
    "        centroid_1 = twrv7.join()\n",
    "        centroid_2 = twrv8.join()\n",
    "        centroid_3 = twrv9.join()\n",
    "        centroid_4 = twrv10.join()\n",
    "        centroid_5 = twrv11.join()\n",
    "        \n",
    "        # Perform the distance of arrival methods to find closest azimuth and colatitude angles\n",
    "        twrv13 = ThreadWithReturnValue(target = difference_of_arrivals, args=(sound_speed,signal_1,algo_name,*mic_locations_1))\n",
    "        twrv14 = ThreadWithReturnValue(target = difference_of_arrivals, args=(sound_speed,signal_2,algo_name,*mic_locations_2))\n",
    "        twrv15 = ThreadWithReturnValue(target = difference_of_arrivals, args=(sound_speed,signal_3,algo_name,*mic_locations_3))\n",
    "        twrv16 = ThreadWithReturnValue(target = difference_of_arrivals, args=(sound_speed,signal_4,algo_name,*mic_locations_4))\n",
    "        twrv17 = ThreadWithReturnValue(target = difference_of_arrivals, args=(sound_speed,signal_5,algo_name,*mic_locations_5))\n",
    "                \n",
    "        twrv13.start()\n",
    "        twrv14.start()\n",
    "        twrv15.start()\n",
    "        twrv16.start()\n",
    "        twrv17.start()\n",
    "\n",
    "        # Desired angles \n",
    "        azimuth_recon_1, colatitude_recon_1 = twrv13.join()\n",
    "        azimuth_recon_2, colatitude_recon_2 = twrv14.join()\n",
    "        azimuth_recon_3, colatitude_recon_3 = twrv15.join()\n",
    "        azimuth_recon_4, colatitude_recon_4 = twrv16.join()\n",
    "        azimuth_recon_5, colatitude_recon_5 = twrv17.join()\n",
    "               \n",
    "        # Desired cartesian coordinates\n",
    "        cartesian_1 = np.array([np.cos(azimuth_recon_1)*np.sin(colatitude_recon_1),np.sin(azimuth_recon_1)*np.sin(colatitude_recon_1),np.cos(colatitude_recon_1)])\n",
    "        cartesian_2 = np.array([np.cos(azimuth_recon_2)*np.sin(colatitude_recon_2),np.sin(azimuth_recon_2)*np.sin(colatitude_recon_2),np.cos(colatitude_recon_2)])\n",
    "        cartesian_3 = np.array([np.cos(azimuth_recon_3)*np.sin(colatitude_recon_3),np.sin(azimuth_recon_3)*np.sin(colatitude_recon_3),np.cos(colatitude_recon_3)])\n",
    "        cartesian_4 = np.array([np.cos(azimuth_recon_4)*np.sin(colatitude_recon_4),np.sin(azimuth_recon_4)*np.sin(colatitude_recon_4),np.cos(colatitude_recon_4)])\n",
    "        cartesian_5 = np.array([np.cos(azimuth_recon_5)*np.sin(colatitude_recon_5),np.sin(azimuth_recon_5)*np.sin(colatitude_recon_5),np.cos(colatitude_recon_5)])\n",
    "                \n",
    "        # Re-center them via adding the centroid\n",
    "        estimate_1 = r*cartesian_1.T + np.array(centroid_1)[np.newaxis,:] \n",
    "        estimate_2 = r*cartesian_2.T + np.array(centroid_2)[np.newaxis,:]\n",
    "        estimate_3 = r*cartesian_3.T + np.array(centroid_3)[np.newaxis,:] \n",
    "        estimate_4 = r*cartesian_4.T + np.array(centroid_4)[np.newaxis,:]\n",
    "        estimate_5 = r*cartesian_5.T + np.array(centroid_5)[np.newaxis,:] \n",
    "                \n",
    "        # Add to an output list\n",
    "        outputs_list.extend((estimate_1, estimate_2, estimate_3, estimate_4, estimate_5))\n",
    "    \n",
    "    # Make a numpy array of them \n",
    "    all_estimates = np.array(outputs_list)\n",
    "    \n",
    "    # Reshape them to (_, 3) which is proper format for the tree\n",
    "    total_array = np.reshape(all_estimates,(all_estimates.shape[0]*all_estimates.shape[1], all_estimates.shape[2]))\n",
    "    \n",
    "    # Re-center the points, add the x,y,z location of the center of the room to the obtained point\n",
    "    room_dim = np.array([0.34925,0.219964,0.2413]) #[13.75,8.66,9.5] # Width,Depth, Depth\n",
    "    centerlist = (room_dim)/2\n",
    "    \n",
    "    # Put the whole list into a tree data data structure\n",
    "    tree = spatial.KDTree(total_array)\n",
    "    \n",
    "    if S1_bool:\n",
    "        # Find the points closest to where S1 sound is\n",
    "        S1_indices = tree.query_ball_point([-0.0639405 , -0.01994509, -0.02030148], 2.5e-2)\n",
    "        estimate = np.array([total_array[S1_indices][j] for j in range(len(S1_indices))])\n",
    "        \n",
    "        # Recenter the S1 source\n",
    "        S_source = np.add(centerlist, np.array([-0.0639405 , -0.01994509, -0.02030148]))\n",
    "    else:\n",
    "        # Find the point closest to where S2 sound is\n",
    "        S2_indices = tree.query_ball_point([-0.09080822, -0.03022343,  0.02206185], 2.5e-2)\n",
    "        estimate = np.array([total_array[S2_indices][j] for j in range(len(S2_indices))])\n",
    "        \n",
    "        # Recenter the S2 Source\n",
    "        S_source = np.add(centerlist, np.array([-0.09080822, -0.03022343,  0.02206185]))\n",
    "    \n",
    "    if estimate.size > 0:                      \n",
    "         # NEW PART: Added in png directly here\n",
    "        source = np.add(centerlist, estimate) # Width, Depth, Length\n",
    "\n",
    "        # Microphone x,y,z locations\n",
    "        x_locations = [-0.102235, -0.052197, -0.027304]\n",
    "        y_locations = [-0.109982]\n",
    "        z_locations = [0.056388, 0.001524, -0.053340, -0.108204]\n",
    "\n",
    "        # Create the microphone array for scatter plot\n",
    "        microphone_locations = [[x,y,z] for x in x_locations for y in y_locations for z in z_locations]\n",
    "\n",
    "        # Add the locations\n",
    "        microphone_source_locations = np.add(centerlist, np.array(microphone_locations))\n",
    "\n",
    "        # Check the bounds: the source list is not empty or that any of the source locations are \n",
    "        # beyond the bounds\n",
    "        if source[source < np.zeros(3)].size == 0 and source[source > room_dim].size == 0:\n",
    "\n",
    "            # Create a Figure, label the axis, Title the plot, and set the limits\n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            ax.set_xlabel('Width (X axis)')\n",
    "            ax.set_ylabel('Depth (Z axis)')\n",
    "            ax.set_zlabel('Length (Y axis)')\n",
    "            ax.set_title(\"All the Clusters\")\n",
    "            ax.set_xlim(0, 0.35)\n",
    "            ax.set_ylim(0, 0.25)\n",
    "            ax.set_zlim(0, 0.22) # for 3-d\n",
    "\n",
    "            # Plot the microphones\n",
    "            ax.scatter(microphone_source_locations[:,0], microphone_source_locations[:,1], microphone_source_locations[:,2], label='Microphones 1-12')\n",
    "\n",
    "            # Plot the S1 or S2 location\n",
    "            ax.scatter(S_source[0], S_source[1], S_source[2], 'b', label='Predicted Source Location')\n",
    "\n",
    "            # Plot all the possible S1 or S2 sounces\n",
    "            ax.scatter(source[:,0], source[:,1], source[:,2], 'y', label='Sources')\n",
    "\n",
    "            ax.legend()\n",
    "\n",
    "            # Write to a csv file to save the data\n",
    "            filename = 'mic_'+str(combinations_number)+'_'+str(source_name)+'_sound_source_localization_c'+str(sound_speed)+'_'+str(algo_name)+'_KDTREE_multithread'\n",
    "\n",
    "            # Save the file\n",
    "            plt.savefig(filename+'.png')\n",
    "            plt.close()\n",
    "\n",
    "            with open(filename+'.csv', mode='w') as sound_source_file:\n",
    "                writer = csv.writer(sound_source_file,delimiter=',')\n",
    "\n",
    "                # First Row of Data, names of the columns\n",
    "                writer.writerow(['Width', 'Depth', 'Length'])\n",
    "\n",
    "                # Write the rest of the results\n",
    "                # Note they have not been converted back into correct x,y,z coordinates\n",
    "                writer.writerows(source) \n",
    "\n",
    "            sound_source_file.close()\n",
    "        else:\n",
    "            print(\"Nothing to convert.Points do not exist inside the boundaries of the environment.\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Nothing to convert: \"+str(source_name)+\"_\"+str(algo_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "    Performs the main script using all the sound data, specific speed of sound, \n",
    "    the names of the distance of arrival methods, and number of combinations of microphone pairs \n",
    "    \"\"\"\n",
    "    # Speed of sound\n",
    "    sound_speed = 30\n",
    "    \n",
    "    # Number of Pairs of Microphone Combinations\n",
    "    combinations_number = 3\n",
    "    \n",
    "    # Data: Number of Cycles for each Sound Source\n",
    "    cycles = ['Cycle'+str(i) for i in range(24)]\n",
    "    soundSources = ['S'+str(i) for i in range(1,3)] \n",
    "    sound_list = [soundSource+'_'+cycle for soundSource in soundSources for cycle in cycles]\n",
    "    \n",
    "    # When to find S1 and S2\n",
    "    S1_bool = True\n",
    "    \n",
    "    # Now test all the algorithms available\n",
    "    algo_names = ['WAVES','CSSM'] #['SRP','MUSIC','TOPS']\n",
    "    \n",
    "    for source_name in sound_list:\n",
    "        for algo_name in algo_names:\n",
    "            \n",
    "            # Check if name is S2\n",
    "            if source_name in ['S'+str(i)+'_'+'Cycle'+str(j) for i in range(2,3) for j in range(24)]:\n",
    "                S1_bool = False\n",
    "            \n",
    "            # Get the Sound Data\n",
    "            sound_data = getData(source_name)\n",
    "\n",
    "            # Get the final results\n",
    "            main(sound_speed,algo_name,sound_data,combinations_number,S1_bool,source_name)\n",
    "            \n",
    "            \n",
    "    print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
